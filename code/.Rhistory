install.packages(c("gridExtra", "quadprog"))
p.Be.wide <- 1-pbeta(0.2,15.2,58.8)
p.Be.narrow <- 1-pbeta(0.2,25.4,82.6)
?integrate
p.Uprior <- integrate(post_Uprior,lower = 0.2,upper=Inf,n=40,y=5)
# prior = U(0.19,0.35):
post_Uprior <- function(p,n,y){
v <- p^y*(1-p)^(n-y)
v[p < 0.19] = 0
v[p > 0.35] = 0
return(36e6*v)
}
const.Uprior <- integrate(post_Uprior,lowe=-Inf,upper=Inf,n=40,y=5)
p.Uprior <- integrate(post_Uprior,lower = 0.2,upper=Inf,n=40,y=5)
p.Uprior <- integrate(post_Uprior,lower = 0.2,upper=Inf,n=40,y=5) / const.Uprior
p.Uprior <- p.Uprior$value / const.Uprior$value
# priors for hitting probability
p <- seq(0,1,0.005)
plot(p,dunif(p,0.19,0.35),type='l',ylim=c(0,10),lwd=2,ylab='density')
lines(p,dbeta(p,10.2,23.8),type='l', lty=2, lwd=2)
lines(p,dbeta(p,20.4,47.6),type='l', lty=3, lwd=2)
legend('topright',
lty=c(1,2,3),lwd=c(2,2,2),
legend = c("U(0.19,0.35)", "Be(10.2,23.8)", "Be(20.4,47.6)")
)
par(mfrow=c(3,1),mar=2*c(1.5,1.5,1.5,1.5))
par(cex=0.85)
# prior = U(0.19,0.35):
post_Uprior <- function(p,n,y){
v <- p^y*(1-p)^(n-y)
v[p < 0.19] = 0
v[p > 0.35] = 0
return(36e6*v)
}
plot(p,dunif(p,0.19,0.35),type='l',lwd=2,ylab='density')
lines(p,30*dbinom(5,40,p),type='l',lty=2,lwd=2)
lines(p,post_Uprior(p,40,5),type='l',lty=3,lwd=2)
title(expression(paste('p(',theta,') = U[0.19,0.35]')))
legend('topright',
lty=c(1,2,3),lwd=c(2,2,2),
legend = c("prior", "likelihood", "posterior")
)
const.Uprior <- integrate(post_Uprior,lowe=-Inf,upper=Inf,n=40,y=5)
p.Uprior <- integrate(post_Uprior,lower = 0.2,upper=Inf,n=40,y=5)
p.Uprior <- p.Uprior$value / const.Uprior$value
# prior = Be(10.2,23.8)
plot(p,dbeta(p,10.2,23.8),type='l',lwd=2,ylab='density')
lines(p,24*dbinom(5,40,p),type='l',lty=2,lwd=2)
lines(p,0.6*dbeta(p,15.2,58.8),type='l',lty=3,lwd=2)
title(expression(paste('p(',theta,') = Be(10.2,23.8)')))
legend('topright',
lty=c(1,2,3),lwd=c(2,2,2),
legend = c("prior", "likelihood", "posterior")
)
p.Be.wide <- 1-pbeta(0.2,15.2,58.8)
# prior = Be(20.4,47.6)
plot(p,0.7*dbeta(p,20.4,47.6),type='l',lwd=2,ylab='density')
lines(p,24*dbinom(5,40,p),type='l',lty=2,lwd=2)
lines(p,0.5*dbeta(p,25.4,82.6),type='l',lty=3,lwd=2)
title(expression(paste('p(',theta,') = Be(20.4,47.6)')))
legend('topright',
lty=c(1,2,3),lwd=c(2,2,2),
legend = c("prior", "likelihood", "posterior")
)
p.Be.narrow <- 1-pbeta(0.2,25.4,82.6)
x <- rnorm(100)
xsort <- sort(x)
hist(x)
par(mfrow=c(1,1))
hist(x)
hist(x,nclass=30)
qqplot(x)
plot(x,qnorm(0.01:1))
plot(x,qnorm(seq(0.01,1,0.01)))
plot(sortx,qnorm(seq(0.01,1,0.01)))
plot(xsort,qnorm(seq(0.01,1,0.01)))
abline(0,1)
x <- rnorm(10000)
xsort <- sort(x)
plot(xsort,qnorm(seq(0.01,1,0.01)))
plot(xsort,qnorm(seq(0.0001,1,0.0001)))
abline(0,1)
quantile(xsort,0.025)
quantile(x,0.025)
x <- c(2,4,4,5,6,8,13)
y <- c(0,0,0,1,1,2,2,2,3,3,3,4,8)
m <- length(x)
n <- length(y)
sx <- sd(x)
sy <- sd(y)
xbar <- mean(x)
ybar <- mean(y)
sp <- sqrt((sum((x-xbar)^2) + sum((y-ybar)^2))/(m+n-2))
# Patil approximation to BF distribution
t <- atan((sx/sqrt(m))/(sy/sqrt(n)))
t.BF <- bfTest(x,y)
# bfTest requires asht package
# Behrens-Fisher distribution
library(asht)
t.BF <- bfTest(x,y)
t.BF$parameter
p.BF <- 1-pbf(-(xbar-ybar)/sqrt(sx^2/m+sy^2/n),n1=m,n2=n,R=t)
N = c(1e7)
simCI <- function(k,x,y){
m <- length(x)
n <- length(y)
sx <- sd(x)
sy <- sd(y)
xbar <- mean(x)
ybar <- mean(y)
lamb <- rt(k,m-1)*(sx/sqrt(m)) + xbar
mu <- rt(k,n-1)*(sy/sqrt(n)) + ybar
diff <- lamb - mu
return(c(quantile(diff,0.025),quantile(diff,0.975),mean(diff>0)))
}
ci.samp <- array(0,c(3,length(N)))
for (i in 1:length(N)){
ci.samp[,i] <- simCI(N[i],x,y)
}
ci.samp
N = c(1e8)
simCI <- function(k,x,y){
m <- length(x)
n <- length(y)
sx <- sd(x)
sy <- sd(y)
xbar <- mean(x)
ybar <- mean(y)
lamb <- rt(k,m-1)*(sx/sqrt(m)) + xbar
mu <- rt(k,n-1)*(sy/sqrt(n)) + ybar
diff <- lamb - mu
return(c(quantile(diff,0.025),quantile(diff,0.975),mean(diff>0)))
}
ci.samp <- array(0,c(3,length(N)))
for (i in 1:length(N)){
ci.samp[,i] <- simCI(N[i],x,y)
}
ci.samp
beta(1,1)
beta(1,3)
beta(3,1)
# data for the beta-binomial model in the form of (n,x,a,b)
data1 <- c(5,3,1/2,1/2)
data2 <- c(25,15,1/2,1/2)
exact.mean <- function(data){
n <- data[1]; x <- data[2]
a <- data[3]; b <- data[4]
return((x+a)/(n+a+b))
}
nnh <- function(t,data){
n <- data[1]; x <- data[2]
a <- data[3]; b <- data[4]
if (t > 1 | t < 0) return(0)
else return((x+a-1)*log(t)+(n-x+b-1)*log(1-t)-log(beta(x+a,n-x+b)))
}
nnh_star <- function(t,data){
n <- data[1]; x <- data[2]
a <- data[3]; b <- data[4]
if (t > 1 | t < 0) return(0)
else return((x+a)*log(t)+(n-x+b-1)*log(1-t)-log(beta(x+a+1,n-x+b)))
}
d2h <- function(t,data){
n <- data[1]; x <- data[2]
a <- data[3]; b <- data[4]
return(((x+a-1)/t^2 + (n-x+b-1)/(1-t)^2)/n)
}
d2h_star <- function(t,data){
n <- data[1]; x <- data[2]
a <- data[3]; b <- data[4]
return(((x+a)/t^2 + (n-x+b-1)/(1-t)^2)/n)
}
mean1 <- exact.mean(data1)
approx.mean <- function(data){
n <- data[1]; x <- data[2]
a <- data[3]; b <- data[4]
t_hat <- (x+a-1)/(n+a+b-2)
t_star <- (x+a)/(n+a+b-1)
sigma_hat <- d2h(t_hat,data)^(-1/2)
sigma_star <- d2h_star(t_star,data)^(-1/2)
return(sigma_star/sigma_hat*exp(nnh_star(t_star,data))/exp(nnh(t_hat,data)))
}
approx.mean1 <- approx.mean(data1)
gamma(1)*gamma(1)/gamma(2)
gamma(1)*gamma(3)/gamma(4)
mean2 <- exact.mean(data2)
approx.mean2 <- approx.mean(data2)
# data for the beta-binomial model in the form of (n,x,a,b)
data1 <- c(5,3,1/2,1/2)
data2 <- c(25,15,1/2,1/2)
exact.mean <- function(data){
n <- data[1]; x <- data[2]
a <- data[3]; b <- data[4]
return((x+a)/(n+a+b))
}
nnh <- function(t,data){
n <- data[1]; x <- data[2]
a <- data[3]; b <- data[4]
if (t > 1 | t < 0) return(0)
else return((x+a-1)*log(t)-(n-x+b-1)*log(1-t)-log(beta(x+a,n-x+b)))
}
nnh_star <- function(t,data){
n <- data[1]; x <- data[2]
a <- data[3]; b <- data[4]
if (t > 1 | t < 0) return(0)
else return((x+a)*log(t)-(n-x+b-1)*log(1-t)-log(beta(x+a+1,n-x+b)))
}
d2h <- function(t,data){
n <- data[1]; x <- data[2]
a <- data[3]; b <- data[4]
v <- (x+a-1)/t^2 + (n-x+b-1)/(1-t)^2
return(v/n)
}
d2h_star <- function(t,data){
n <- data[1]; x <- data[2]
a <- data[3]; b <- data[4]
v <- (x+a)/t^2 + (n-x+b-1)/(1-t)^2
return(v/n)
}
approx.mean <- function(data){
n <- data[1]; x <- data[2]
a <- data[3]; b <- data[4]
t_hat <- (x+a-1)/(n+a+b-2)
t_star <- (x+a)/(n+a+b-1)
sigma_hat <- d2h(t_hat,data)^(-1/2)
sigma_star <- d2h_star(t_star,data)^(-1/2)
return(sigma_star/sigma_hat*exp(nnh_star(t_star,data))/exp(nnh(t_hat,data)))
}
mean1 <- exact.mean(data1)
approx.mean1 <- approx.mean(data1)
mean2 <- exact.mean(data2)
approx.mean2 <- approx.mean(data2)
optim(0.5,nnh)
optimize(0.5,nnh)
optimize(nnh,c(0,1))
optimize(nnh,c(0,1),data=data1)
optimize(-nnh,c(0,1),data=data1)
optimize(nnh,c(0,1),data=data1,maximum = TRUE)
t=seq(0,1,0.01)
nnhT <- nnh(t,data=data1)
for (i in 1:101){}
for (i in 1:101){
nnhT[i] <- nnh(t[i],data1)
}
plot(nnhT)
nnh <- function(t,data){
n <- data[1]; x <- data[2]
a <- data[3]; b <- data[4]
if (t > 1 | t < 0) return(0)
else return((x+a-1)*log(t)+(n-x+b-1)*log(1-t))
}
optimize(nnh,c(0,1),data=data1,maximum = TRUE)
nnh <- function(t,data){
n <- data[1]; x <- data[2]
a <- data[3]; b <- data[4]
if (t > 1 | t < 0) return(0)
else return((x+a-1)*log(t)+(n-x+b-1)*log(1-t)-log(beta(x+a,n-x+b)))
}
optimize(nnh,c(0,1),data=data1,maximum = TRUE)
nnh_star <- function(t,data){
n <- data[1]; x <- data[2]
a <- data[3]; b <- data[4]
if (t > 1 | t < 0) return(0)
else return((x+a)*log(t)+(n-x+b-1)*log(1-t)-log(beta(x+a+1,n-x+b)))
}
optimize(nnh_star,c(0,1),data=data1,maximum = TRUE)
(x+a)/(n+a+b-1)
a <- data[3]; b <- data[4]
n <- data[1]; x <- data[2]
approx.mean <- function(data){
n <- data[1]; x <- data[2]
a <- data[3]; b <- data[4]
t_hat <- optimize(nnh,c(0,1),maximum=TRUE,data=data)$maximum
t_star <- optimize(nnh_star,c(0,1),maximum=TRUE,data=data)$maximum
sigma_hat <- d2h(t_hat,data)^(-1/2)
sigma_star <- d2h_star(t_star,data)^(-1/2)
return(sigma_star/sigma_hat*exp(nnh_star(t_star,data))/exp(nnh(t_hat,data)))
}
mean1 <- exact.mean(data1)
approx.mean1 <- approx.mean(data1)
3.5/6
knitr::opts_chunk$set(echo = TRUE)
library(logisticPCA)
ftrain <- read.table('ftrain.txt')
setwd("C:/Users/moses/Desktop/git/binary-hd-emulator/code")
library(logisticPCA)
ftrain <- read.table('ftrain.txt')
library(logisticPCA)
ftrain <- read.table('ftrain.txt')
ytrain <- is.na(ftrain)
model <- logisticPCA(ytrain)
model <- logisticPCA(ytrain, k=10)
# construct a low rank matrices in the logit scale
rows = 100
cols = 10
set.seed(1)
loadings = rnorm(cols)
mat_logit = outer(rnorm(rows), loadings)
mat_logit_new = outer(rnorm(rows), loadings)
# convert to a binary matrix
mat = (matrix(runif(rows * cols), rows, cols) <= inv.logit.mat(mat_logit)) * 1.0
mat_new = (matrix(runif(rows * cols), rows, cols) <= inv.logit.mat(mat_logit_new)) * 1.0
# run logistic PCA on it
lpca = logisticPCA(mat, k = 1, m = 4, main_effects = FALSE)
PCs = predict(lpca, mat_new)
knitr::opts_chunk$set(echo = TRUE)
library(logisticPCA)
f <- read.table('f.txt')
y <- is.na(f)
theta <- read.table('theta.txt')
# logisticPCA takes an n x d matrix, n = number of parameters, d = dimension of output (to be reduced)
# model <- logisticPCA(t(y), k=10)
y <- as.matrix(is.na(f))
y <- as.numeric(is.na(f))
y <- as.data.frame(is.na(f))
knitr::opts_chunk$set(echo = TRUE)
thetatest <- data.frame(theta=theta[-traininds, ])
N <- dim(y)[2]
traininds <- sample(1:1000, 500, replace=T)
ytrain <- y[traininds, ]
thetatrain <- theta[traininds, ]
thetatest <- data.frame(theta=theta[-traininds, ])
store = list()
for (i in 1:N){
data <- data.frame(y=ytrain[, i], theta=thetatrain)
store[[i]] <- glm(y ~ ., family = binomial(link = "logit"), data = data)
}
trainpred <- data.frame(matrix(unlist(lapply(store, function(model) model$fitted.values)), ncol=N))
testpred <- data.frame(matrix(unlist(lapply(store, function(model) predict.glm(model, newdata=thetatest, type='response'))), ncol=N))
library(logisticPCA)
f <- read.table('f.txt')
y <- as.data.frame(t(is.na(f)))
theta <- as.data.frame(read.table('theta.txt'))
# logisticPCA takes an n x d matrix, n = number of parameters, d = dimension of output (to be reduced)
# model <- logisticPCA(t(y), k=10)
N <- dim(y)[2]
traininds <- sample(1:1000, 500, replace=T)
ytrain <- y[traininds, ]
thetatrain <- theta[traininds, ]
thetatest <- data.frame(theta=theta[-traininds, ])
store = list()
for (i in 1:N){
data <- data.frame(y=ytrain[, i], theta=thetatrain)
store[[i]] <- glm(y ~ ., family = binomial(link = "logit"), data = data)
}
trainpred <- data.frame(matrix(unlist(lapply(store, function(model) model$fitted.values)), ncol=N))
testpred <- data.frame(matrix(unlist(lapply(store, function(model) predict.glm(model, newdata=thetatest, type='response'))), ncol=N))
traininds
dim(theta[traininds, ])
dim(theta[-traininds, ])
N <- dim(y)[2]
traininds <- sample(1:1000, 500, replace=F)
ytrain <- y[traininds, ]
thetatrain <- theta[traininds, ]
thetatest <- data.frame(theta=theta[-traininds, ])
store = list()
for (i in 1:N){
data <- data.frame(y=ytrain[, i], theta=thetatrain)
store[[i]] <- glm(y ~ ., family = binomial(link = "logit"), data = data)
}
trainpred <- data.frame(matrix(unlist(lapply(store, function(model) model$fitted.values)), ncol=N))
testpred <- data.frame(matrix(unlist(lapply(store, function(model) predict.glm(model, newdata=thetatest, type='response'))), ncol=N))
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
library(logisticPCA)
f <- read.table('f.txt')
y <- as.data.frame(t(is.na(f)))
theta <- as.data.frame(read.table('theta.txt'))
# logisticPCA takes an n x d matrix, n = number of parameters, d = dimension of output (to be reduced)
# model <- logisticPCA(t(y), k=10)
N <- dim(y)[2]
traininds <- sample(1:1000, 500, replace=F)
ytrain <- y[traininds, ]
thetatrain <- theta[traininds, ]
thetatest <- data.frame(theta=theta[-traininds, ])
store = list()
for (i in 1:N){
data <- data.frame(y=ytrain[, i], theta=thetatrain)
store[[i]] <- glm(y ~ ., family = binomial(link = "logit"), data = data)
}
trainpred <- data.frame(matrix(unlist(lapply(store, function(model) model$fitted.values)), ncol=N))
testpred <- data.frame(matrix(unlist(lapply(store, function(model) predict.glm(model, newdata=thetatest, type='response'))), ncol=N))
XX <- matrix(seq(-1, 2 * pi + 1, length = 499), ncol = ncol(X))
X <- matrix(seq(0, 2 * pi,length = 6), ncol = 1)
XX <- matrix(seq(-1, 2 * pi + 1, length = 499), ncol = ncol(X))
library(laGP\)
library(laGP)
gc()
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
library(logisticPCA)
f <- read.table('f.txt')
y <- as.data.frame(t(is.na(f)))
theta <- as.data.frame(read.table('theta.txt'))
# logisticPCA takes an n x d matrix, n = number of parameters, d = dimension of output (to be reduced)
# model <- logisticPCA(t(y), k=10)
N <- dim(y)[2]
traininds <- sample(1:1000, 500, replace=F)
ytrain <- y[traininds, ]
ytest <- y[-traininds, ]
thetatrain <- theta[traininds, ]
thetatest <- data.frame(theta=theta[-traininds, ])
# logistic regression over each column
store = list()
for (i in 1:N){
data <- data.frame(y=ytrain[, i], theta=thetatrain)
store[[i]] <- glm(y ~ ., family = binomial(link = "logit"), data = data)
}
trainpred <- data.frame(matrix(unlist(lapply(store, function(model) model$fitted.values)), ncol=N))
testpred <- data.frame(matrix(unlist(lapply(store, function(model) predict.glm(model, newdata=thetatest, type='response'))), ncol=N))
angle <- function(p,y){
# transform p and y from [0, 1] to [-1, 1]
p <- 2*as.numeric(p) - 1
y <- 2*as.numeric(y) - 1
norm.p <- norm(p,type="2")
norm.y <- norm(y,type="2")
sp <- p%*%y  / (norm.p * norm.y)
}
trainscore <- mean(sapply(1:500, function(i) angle(ytrain[i, ], trainpred[i, ])))
testscore <- mean(sapply(1:500, function(i) angle(ytest[i, ], testpred[i, ])))
getLPCAmodels <- function(inds, k){
yboot <- y[inds,]
model <- logisticPCA(yboot, k)
return(model)
}
K <- 25
ks <- c(seq(1, K, 4), 35, 50, 60, 75, 100, 150, 198)
explained_dev <- matrix("numeric", nrow=length(ks), ncol=2)
for (i in 1:length(ks)){
k <- ks[i]
m <- getLPCAmodels(1:dim(y)[2], k)
explained_dev[i, 1] <- k
explained_dev[i, 2] <- m$prop_deviance_expl
}
plot(explained_dev, type ='b',
ylim = c(0, 1),
xlab = 'number of PCs',
ylab = 'explained proportion of dev')
text(150, 0.75, paste('max = ', signif(as.numeric(tail(explained_dev, 1)[2]), 3)))
plot(explained_dev, type ='b',
ylim = c(0, 1),
xlab = 'number of PCs',
ylab = 'explained proportion of dev')
text(150, 0.75, paste('max = ', signif(as.numeric(tail(explained_dev, 1)[2]), 3)))
explained_dev
